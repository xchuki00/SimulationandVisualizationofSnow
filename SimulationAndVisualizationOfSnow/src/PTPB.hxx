
#ifndef __PTPB_HXX__
#define __PTPB_HXX__

#include <vector>
#include <cmath>
#include "PTPBBeams.hxx"
#include "Beams\PhBeams.hxx"
#include "Bre\Bre.hxx"
#include "Misc\HashGrid.hxx"
#include "Misc\Timer.hxx"
#include "Path\PathWeight.hxx"
#include "Renderers\Renderer.hxx"
#include "PTPBBeam.hxx"
#define PTPB_CAMERA_MAXVERTS 1001
#define PTPB_LIGHT_AVGVERTS 20

class PTPB : public AbstractRenderer
{
	// The sole point of this structure is to make carrying around the ray baggage easier.
	struct SubPathState
	{
		Pos   mOrigin;             // Path origin
		Dir   mDirection;          // Where to go next
		Rgb   mThroughput;         // Path throughput           
		uint  mPathLength : 30;    // Number of path segments, including this
		uint  mIsFiniteLight : 1;  // Just generated by finite light
		uint  mSpecularPath : 1;   // All scattering events so far were specular 
		bool  mLastSpecular;       // Last sampled event was specular
		float mLastPdfWInv;        // PDF of the last sampled direction

		BoundaryStack mBoundaryStack; // Stack of crossed boundaries		
	};

	// Range query used for PPM, BPM, and PTPB. When HashGrid finds a vertex
	// within range -- Process() is called and vertex
	// merging is performed. BSDF of the camera vertex is used.
	class RangeQuery
	{
	public:

		RangeQuery(
			const PTPB& aPTPB,
			const Pos& aCameraPosition,
			const BSDF& aCameraBsdf,
			const SubPathState& aCameraState,
			const DebugImages& aDebugImages
		) :
			mPTPB(aPTPB),
			mCameraPosition(aCameraPosition),
			mCameraBsdf(aCameraBsdf),
			mCameraState(aCameraState),
			mContrib(0),
			mDebugImages(aDebugImages)
		{}

		const Pos& GetPosition() const { return mCameraPosition; }

		const Rgb& GetContrib() const { return mContrib; }

		void Process(const UPBPLightVertex& aLightVertex)
		{
			// We store all light vertices but not all can be used for merging (delta and light)
			if (!aLightVertex.mConnectable)
				return;

			// Use only vertices with same location (on surface/in medium)
			UPBP_ASSERT(aLightVertex.mInMedium == mCameraBsdf.IsInMedium());

			// Reject if full path length below/above min/max path length
			if ((aLightVertex.mPathLength + mCameraState.mPathLength > mPTPB.mMaxPathLength) ||
				(aLightVertex.mPathLength + mCameraState.mPathLength < mPTPB.mMinPathLength))
				return;

			// Retrieve light incoming direction in world coordinates
			const Dir lightDirection = aLightVertex.mBSDF.WorldDirFix();

			float cosCamera, cameraBsdfDirPdfW, cameraBsdfRevPdfW, sinTheta;
			const Rgb cameraBsdfFactor = mCameraBsdf.Evaluate(
				lightDirection, cosCamera, &cameraBsdfDirPdfW,
				&cameraBsdfRevPdfW, &sinTheta);

			if (cameraBsdfFactor.isBlackOrNegative())
				return;

			cameraBsdfDirPdfW *= mCameraBsdf.ContinuationProb();
			UPBP_ASSERT(cameraBsdfDirPdfW > 0);

			// Even though this is PDF from camera BSDF, the continuation probability
			// must come from light BSDF, because that would govern it if light path
			// actually continued
			cameraBsdfRevPdfW *= aLightVertex.mBSDF.ContinuationProb();
			UPBP_ASSERT(cameraBsdfRevPdfW > 0);

			// MIS weight
			float misWeight = 1.0f;
			if (mPTPB.mAlgorithm != kPPM)
			{
				const float misWeightFactorInv = 1.0f / (aLightVertex.mInMedium ? aLightVertex.mMisData.mPP3DMisWeightFactor : aLightVertex.mMisData.mSurfMisWeightFactor);
				const float wCamera = mPTPB.AccumulateCameraPathWeight2(mCameraState.mPathLength, misWeightFactorInv, sinTheta, aLightVertex.mMisData.mRaySamplePdfInv, aLightVertex.mMisData.mRaySamplePdfsRatio, cameraBsdfRevPdfW);
				const float wLight = mPTPB.AccumulateLightPathWeight2(aLightVertex.mPathIdx, aLightVertex.mPathLength, misWeightFactorInv, 0, 0, 0, cameraBsdfDirPdfW, aLightVertex.mInMedium ? PP3D : SURF, false);
				misWeight = 1.f / (wLight + wCamera);
			}

			const Rgb mult = cameraBsdfFactor * aLightVertex.mThroughput;
			mContrib += misWeight * mult;
			mDebugImages.accumRgbWeight(aLightVertex.mPathLength, aLightVertex.mInMedium ? DebugImages::PP3D : DebugImages::SURFACE_PHOTON_MAPPING, mult, misWeight);
		}

	private:

		const PTPB& mPTPB;
		const Pos& mCameraPosition;
		const BSDF& mCameraBsdf;
		const SubPathState& mCameraState;
		Rgb                mContrib;
		const DebugImages& mDebugImages;
	};

public:

	enum AlgorithmType
	{
		kLT = 0,   // light tracing
		kPTdir,    // direct path tracing
		kPTls,     // path tracing with light sampling
		kPTmis,    // path tracing with MIS
		kBPT,      // bidirectional path tracing
		kPPM,      // camera and light vertices merged on first non-specular surface from camera (cannot handle mixed specular + non-specular materials)
		kBPM,      // camera and light vertices merged on along full path
		kVCM,      // vertex connection and merging
		kCustom    // combination of techniques (BPT, SURF, PP3D, PB2D, BB1D) specified using flags
	};

	PTPB(
		const Scene& aScene,
		const AlgorithmType     aAlgorithm,
		const uint              aEstimatorTechniques,
		const BeamType          aQueryBeamType,
		const float 	        aBB1DRadiusInitial,
		const float             aBB1DRadiusAlpha,
		const RadiusCalculation aBB1DRadiusCalculation,
		const int		        aBB1DRadiusKNN,
		const BeamType          aPhotonBeamType,
		const float             aBB1DUsedLightSubPathCount,
		const float             aBB1DBeamStorageFactor,
		const float             aRefPathCountPerIter,
		const float             aPathCountPerIter,
		const float             aMinDistToMed,
		const size_t			aMaxMemoryPerThread,
		const int               aSeed = 1234,
		const int               aBaseSeed = 1234,
		const bool				aIgnoreFullySpecPaths = false,
		const bool              aVerbose = false) :
		AbstractRenderer(aScene),
		Evaluator(aScene),
		mAlgorithm(aAlgorithm),
		mEstimatorTechniques(aEstimatorTechniques),
		mBB1DRadiusAlpha(aBB1DRadiusAlpha),
		mBB1DRadius(aBB1DRadiusInitial),
		mBB1DRadiusCalculation(aBB1DRadiusCalculation),
		mBB1DRadiusKNN(aBB1DRadiusKNN),
		mPhotonBeamType(aPhotonBeamType),
		mBB1DUsedLightSubPathCount(aBB1DUsedLightSubPathCount),
		mBB1DBeamStorageFactor(aBB1DBeamStorageFactor),
		mRefPathCountPerIter(aRefPathCountPerIter),
		mPathCountPerIter(aPathCountPerIter),
		mMinDistToMed(aMinDistToMed),
		mMaxMemoryPerThread(aMaxMemoryPerThread),
		mIgnoreFullySpecPaths(aIgnoreFullySpecPaths),
		mRng(aSeed),
		mBaseSeed(aBaseSeed),
		mVerbose(aVerbose)
	{

		if (mBB1DRadius < 0)
			mBB1DRadius = -mBB1DRadius * mScene.mSceneSphere.mSceneRadius;
		UPBP_ASSERT(mBB1DRadius > 0);

		if (mMinDistToMed < 0)
			mMinDistToMed = -mMinDistToMed * mScene.mSceneSphere.mSceneRadius;
		UPBP_ASSERT(mMinDistToMed >= 0);
		mTraceLightPaths = mEstimatorTechniques != 0;
		mTraceCameraPaths = mEstimatorTechniques != 0;
		mConnectToCamera = mEstimatorTechniques & BPT;
		mConnectToLightSource = mEstimatorTechniques & BPT;
		mConnectToLightVertices = mEstimatorTechniques & BPT;
		mMergeWithLightVerticesBB1D = mEstimatorTechniques & BB1D;


	}

	virtual void RunIteration(int aIteration)
	{
		// Get path count, one path for each pixel
		const int resX = int(mScene.mCamera.mResolution.get(0));
		const int resY = int(mScene.mCamera.mResolution.get(1));
		int pathCountC = resX * resY;
		int pathCountL = mPathCountPerIter;

		// We don't have the same number of pixels (camera paths)
		// and light paths
		mScreenPixelCount = float(pathCountC);
		mLightSubPathCount = mPathCountPerIter;
		std::cout << "techniques: " << mEstimatorTechniques << std::endl;
		if (!(mEstimatorTechniques & SPECULAR_ONLY))
		{
			// To make list of photons and beams same in previous and compatible mode
			mRng = Rng(mBaseSeed + aIteration);
			Evaluator.mSeed = mBaseSeed + aIteration;

			if (mBB1DUsedLightSubPathCount < 0)
				mBB1DUsedLightSubPathCount = std::floor(-mBB1DUsedLightSubPathCount * mLightSubPathCount);

			// Radius reduction (1st iteration has aIteration == 0, thus offset)
			const float effectiveIteration = 1 + aIteration * mLightSubPathCount / mRefPathCountPerIter;
			// BB1D
			mBB1DRadius = mBB1DRadius * sqrt((aIteration+2/3)/aIteration+1);
			mBB1DRadius = std::max(mBB1DRadius, 1e-7f); // Purely for numeric stability

			// Constant for decision whether to store beams or not
			mBB1DMinMFP = mBB1DBeamStorageFactor * 0.5f * PI_F * mBB1DRadius;
			if (mVerbose) std::cout << "min mfp: " << mBB1DMinMFP << std::endl;

			const float etaBB1D = 0.5f * mBB1DRadius * mBB1DUsedLightSubPathCount;

			// Factor used to normalize vertex merging contribution.
			// We divide the summed up energy by disk radius and number of light paths
			mBB1DNormalization = 1.f / mBB1DUsedLightSubPathCount;

			// MIS weight constants
			mBB1DMisWeightFactor = etaBB1D;

			// Clear path ends, nothing ends anywhere
			mPathEnds.resize(pathCountL);
			memset(&mPathEnds[0], 0, mPathEnds.size() * sizeof(int));

			// Because of static mCameraVerticesMisData size
			UPBP_ASSERT(mMaxPathLength < PTPB_CAMERA_MAXVERTS);

			const float maxLightVerts = std::min(mLightSubPathCount * std::min((int)mMaxPathLength, PTPB_LIGHT_AVGVERTS), (float)mMaxMemoryPerThread / sizeof(UPBPLightVertex));
			const float maxBeams = std::min(mBB1DUsedLightSubPathCount * std::min((int)mMaxPathLength, PTPB_LIGHT_AVGVERTS), (float)mMaxMemoryPerThread / sizeof(UPBPLightVertex));

			if (mVerbose)
				std::cout << "allocating : " << ((int)maxLightVerts) << std::endl;

			// Remove all light vertices and reserve space for some		
			mLightVertices.clear();
			mLightVertices.reserve((int)maxLightVerts);

			if (mVerbose)
				std::cout << "allocating : " << mLightVertices.capacity() << std::endl;
			UPBP_ASSERT(mLightVertices.size() == 0 && mLightVertices.capacity() >= (int)maxLightVerts);

			// Remove all photon beams and reserve space for some
			mPhotonBeamsArray.clear();
			mPhotonBeamsArray.reserve((int)maxBeams);
			UPBP_ASSERT(mPhotonBeamsArray.size() == 0 && mPhotonBeamsArray.capacity() >= (int)maxBeams);

			mLightVerticesOnSurfaceCount = 0;
			mLightVerticesInMediumCount = 0;

			//////////////////////////////////////////////////////////////////////////
			// Generate light paths
			//////////////////////////////////////////////////////////////////////////

			if (mVerbose)
				std::cout << " + tracing light sub-paths..." << std::endl;

			mTimer.Start();

			// If pure path tracing is used, there are no lights or only one path segment is allowed, light tracing step is skipped
			if (mTraceLightPaths && mScene.GetLightCount() > 0 && mMaxPathLength > 1)
				for (int pathIdx = 0; pathIdx < pathCountL; pathIdx++)
				{
					// Generate light path origin and direction
					SubPathState lightState;
					GenerateLightSample(pathIdx, lightState);

					// In attenuating media the ray can never travel from infinity
					if (!lightState.mIsFiniteLight && mScene.GetGlobalMediumPtr()->HasAttenuation())
					{
						mPathEnds[pathIdx] = (int)mLightVertices.size();
						continue;
					}

					// We assume that the light is on surface
					bool originInMedium = false;
					float distance = 0;
					//////////////////////////////////////////////////////////////////////////
					// Trace light path
					for (;; ++lightState.mPathLength)
					{
						// Prepare ray
						Ray ray(lightState.mOrigin, lightState.mDirection);
						Isect isect(1e36f);

						// Trace ray
						mVolumeSegments.clear();
						mLiteVolumeSegments.clear();
						bool intersected = mScene.Intersect(ray, originInMedium ? AbstractMedium::kOriginInMedium : 0, mRng, isect, lightState.mBoundaryStack, mVolumeSegments, mLiteVolumeSegments);
						float previusDistance = 0;

						// Store beam if required
						if (mMergeWithLightVerticesBB1D && pathIdx < mBB1DUsedLightSubPathCount)
						{
							if (!mPhotonBeamsArray.empty()) {
								previusDistance = mPhotonBeamsArray.back().mDistance;
							}
							AddBeams(ray, lightState.mThroughput, &mLightVertices.back(), originInMedium ? AbstractMedium::kOriginInMedium : 0, lightState.mLastPdfWInv);
							mPhotonBeamsArray.back().mDistance = previusDistance + distance;
						}

						if (!intersected)
							break;

						UPBP_ASSERT(isect.IsValid());

						// Attenuate by intersected media (if any)
						float raySamplePdf(1.0f);
						float raySampleRevPdf(1.0f);
						if (!mVolumeSegments.empty())
						{
							// PDF
							raySamplePdf = VolumeSegment::AccumulatePdf(mVolumeSegments);
							UPBP_ASSERT(raySamplePdf > 0);

							// Reverse PDF
							raySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
							UPBP_ASSERT(raySampleRevPdf > 0);

							// Attenuation
							lightState.mThroughput *= VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments) / raySamplePdf;
						}

						if (lightState.mThroughput.isBlackOrNegative())
							break;

						// Prepare scattering function at the hitpoint (BSDF/phase depending on whether the hitpoint is at surface or in media, the isect knows)
						BSDF bsdf(ray, isect, mScene, BSDF::kFromLight, mScene.RelativeIOR(isect, lightState.mBoundaryStack));

						if (!bsdf.IsValid()) // e.g. hitting surface too parallel with tangent plane
							break;

						// Compute hitpoint
						const Pos hitPoint = ray.origin + ray.direction * isect.mDist;
						

						originInMedium = isect.IsInMedium();
						float speed = mDefaultLightSpeed;

						if (originInMedium) {
							speed /= 1.5; //TODO
						}
						distance = isect.mDist / speed;

						// Store vertex
						{
							UPBPLightVertex lightVertex;
							lightVertex.mHitpoint = hitPoint;
							lightVertex.mThroughput = lightState.mThroughput;
							lightVertex.mPathIdx = pathIdx;
							lightVertex.mPathLength = lightState.mPathLength;
							lightVertex.mInMedium = originInMedium;
							lightVertex.mConnectable = !bsdf.IsDelta();
							lightVertex.mIsFinite = true;
							lightVertex.mBSDF = bsdf;

							// Determine whether the vertex is in medium behind real geometry
							lightVertex.mBehindSurf = false;
							if (lightVertex.mInMedium && !lightState.mBoundaryStack.IsEmpty())
							{
								int matId = lightState.mBoundaryStack.Top().mMaterialId;
								if (matId >= 0)
								{
									const Material& mat = mScene.GetMaterial(matId);
									if (mat.mGeometryType != GeometryType::IMAGINARY)
										lightVertex.mBehindSurf = true;
								}
							}

							// Infinite lights use MIS handled via solid angle integration, so do not divide by the distance for such lights
							const float distSq = (lightState.mPathLength > 1 || lightState.mIsFiniteLight == 1) ? Utils::sqr(isect.mDist) : 1.0f;
							const float raySamplePdfInv = 1.0f / raySamplePdf;
							lightVertex.mMisData.mPdfAInv = lightState.mLastPdfWInv * distSq * raySamplePdfInv / std::abs(bsdf.CosThetaFix());
							lightVertex.mMisData.mRevPdfA = 1.0f;
							lightVertex.mMisData.mRevPdfAWithoutBsdf = lightVertex.mMisData.mRevPdfA;
							lightVertex.mMisData.mRaySamplePdfInv = raySamplePdfInv;
							lightVertex.mMisData.mRaySampleRevPdfInv = 1.0f;
							lightVertex.mMisData.mSinTheta = 0.0f;
							lightVertex.mMisData.mCosThetaOut = 0.0f;
							lightVertex.mMisData.mBB1DMisWeightFactor = bsdf.IsOnSurface() ? 0 : mBB1DMisWeightFactor;
							lightVertex.mMisData.mBB1DBeamSelectionPdf = bsdf.IsOnSurface() ? 0 : 1;
							lightVertex.mMisData.mIsDelta = bsdf.IsDelta();
							lightVertex.mMisData.mIsOnLightSource = false;
							lightVertex.mMisData.mIsSpecular = false;
							lightVertex.mMisData.mInMediumWithBeams = bsdf.IsOnSurface() ? false : (bsdf.GetMedium()->GetMeanFreePath(hitPoint) > mBB1DMinMFP);

							lightVertex.mMisData.mRaySamplePdfsRatio = 0.0f;
							lightVertex.mMisData.mRaySampleRevPdfsRatio = 0.0f;
							if (bsdf.IsInMedium())
							{
								if (bsdf.GetMedium()->IsHomogeneous())
								{
									lightVertex.mMisData.mRaySamplePdfsRatio = 1.0f / ((const HomogeneousMedium*)bsdf.GetMedium())->mMinPositiveAttenuationCoefComp();
									lightVertex.mMisData.mRaySampleRevPdfsRatio = lightVertex.mMisData.mRaySamplePdfsRatio;
								}
								else
								{
									const float lastSegmentRayOverSamplePdf = bsdf.GetMedium()->RaySamplePdf(ray, mVolumeSegments.back().mDistMin, mVolumeSegments.back().mDistMax, 0);
									const float lastSegmentRayInSamplePdf = mVolumeSegments.back().mRaySamplePdf; // We are in medium -> we know we have insampled
									lightVertex.mMisData.mRaySamplePdfsRatio = lastSegmentRayOverSamplePdf / lastSegmentRayInSamplePdf;
								}
							}

							// Update reverse PDFs of the previous vertex
							mLightVertices.back().mMisData.mRevPdfA *= raySampleRevPdf / distSq;
							mLightVertices.back().mMisData.mRevPdfAWithoutBsdf = mLightVertices.back().mMisData.mRevPdfA;
							mLightVertices.back().mMisData.mRaySampleRevPdfInv = 1.0f / raySampleRevPdf;

							if (mLightVertices.back().mBSDF.IsInMedium() && !mLightVertices.back().mBSDF.GetMedium()->IsHomogeneous()) // Homogeneous case was solved immediately when processing the vertex for the first time
							{
								float firstSegmentRayOverSampleRevPdf;
								mLightVertices.back().mBSDF.GetMedium()->RaySamplePdf(ray, mVolumeSegments.front().mDistMin, mVolumeSegments.front().mDistMax, 0, &firstSegmentRayOverSampleRevPdf);
								const float firstSegmentRayInSampleRevPdf = mVolumeSegments.front().mRaySampleRevPdf; // We were in medium -> we know we have insampled
								mLightVertices.back().mMisData.mRaySampleRevPdfsRatio = firstSegmentRayOverSampleRevPdf / firstSegmentRayInSampleRevPdf;
							}

							if (lightVertex.mInMedium)
								mLightVerticesInMediumCount++;
							else
								mLightVerticesOnSurfaceCount++;

							UPBP_ASSERT(mLightVertices.size() < mLightVertices.capacity());
							mLightVertices.push_back(lightVertex);
						}

						// Connect to camera, unless scattering function is purely specular or we are not allowed to connect from surface
						if (mConnectToCamera && !bsdf.IsDelta() && (bsdf.IsInMedium()))
						{
							if (lightState.mPathLength + 1 >= mMinPathLength)
								ConnectToCamera(pathIdx, lightState, hitPoint, bsdf, mLightVertices.back().mMisData.mRaySamplePdfsRatio);
						}

						// Terminate if the path would become too long after scattering
						if (lightState.mPathLength + 2 > mMaxPathLength)
							break;

						// Continue random walk
						if (!SampleScattering(bsdf, hitPoint, isect, lightState, mLightVertices.back().mMisData, mLightVertices.at(mLightVertices.size() - 2).mMisData))
							break;
					}

					mPathEnds[pathIdx] = (int)mLightVertices.size();
				}

			mTimer.Stop();
			if (mVerbose)
				std::cout << "    - light sub-path tracing done in " << mTimer.GetLastElapsedTime() << " sec. " << std::endl;

			int photons = 0;

			if (mMaxPathLength > 1)
			{
				//////////////////////////////////////////////////////////////////////////
				// Build acceleration structure for BB1D
				//////////////////////////////////////////////////////////////////////////
				if (mMergeWithLightVerticesBB1D && !mPhotonBeamsArray.empty())
				{
					Evaluator.build(mPhotonBeamsArray, mBB1DRadiusCalculation, mBB1DRadius, mBB1DRadiusKNN, mVerbose);

					// Set beam selection PDFs according to the built structure
					if (Evaluator.sMaxBeamsInCell)
						for (std::vector<UPBPLightVertex>::iterator i = mLightVertices.begin(); i != mLightVertices.end(); ++i)
						{
							if (i->mBSDF.IsInMedium())
								i->mMisData.mBB1DBeamSelectionPdf = Evaluator.getBeamSelectionPdf(i->mHitpoint);
						}
				}
			}
		}
		//////////////////////////////////////////////////////////////////////////
		// Generate camera paths
		//////////////////////////////////////////////////////////////////////////

		if (mVerbose)
			std::cout << " + tracing camera sub-paths..."<<mEstimatorTechniques << std::endl;
		mTimer.Start();

		// Unless rendering with traditional light tracing
		if (mTraceCameraPaths)
			for (int pathIdx = 0; pathIdx < pathCountC; ++pathIdx)
			{
				// Generate camera path origin and direction			
				SubPathState cameraState;
				const Vec2f screenSample = GenerateCameraSample(pathIdx, cameraState);
				Rgb color(0);

				// We assume that the camera is on surface
				bool originInMedium = false;

				// Medium of the previous vertex
				const AbstractMedium* lastMedium = NULL;

				bool onlySpecSurf = (mEstimatorTechniques & (PREVIOUS | COMPATIBLE)) != 0;
				bool stopBB1D = false;
				float distance = 0;
				//////////////////////////////////////////////////////////////////////
				// Trace camera path
				for (;; ++cameraState.mPathLength)
				{
					// Prepare ray
					Ray ray(cameraState.mOrigin, cameraState.mDirection);
					Isect isect(1e36f);

					// Trace ray
					mVolumeSegments.clear();
					mLiteVolumeSegments.clear();
					if (!mScene.Intersect(ray, originInMedium ? AbstractMedium::kOriginInMedium : 0, mRng, isect, cameraState.mBoundaryStack, mVolumeSegments, mLiteVolumeSegments))
					{
						//UPBP_ASSERT(!mScene.GetGlobalMediumPtr()->HasScattering());			

						// Vertex merging: beam x beam 1D
						if (mMergeWithLightVerticesBB1D && !mPhotonBeamsArray.empty() && !stopBB1D)
						{
							uint estimatorTechniques = mEstimatorTechniques;
							//if (!cameraState.mSpecularPath) estimatorTechniques |= BEAM_REDUCTION;
							embree::AdditionalRayDataForMis data(&mLightVertices, &mPathEnds, &mCameraVerticesMisData, cameraState.mPathLength, mMinPathLength, mMaxPathLength, BeamType::LONG_BEAM, mPhotonBeamType, cameraState.mLastPdfWInv, 0, 0, 0, mBB1DMisWeightFactor, !mPhotonBeamsArray.empty() ? &Evaluator : NULL, mBB1DMinMFP, mBB1DUsedLightSubPathCount, mMinDistToMed, 0.0f, 0.0f, 0, &mDebugImages);
							const Rgb contrib = Evaluator.evalBeamBeamEstimate(BeamType::LONG_BEAM, ray, mVolumeSegments,distance, estimatorTechniques, originInMedium ? AbstractMedium::kOriginInMedium : 0, &data);
							const Rgb mult = cameraState.mThroughput * mBB1DNormalization;
							color += mult * contrib;
							////std::cout << "contrib: " << contrib << std::endl;
							//std::cout << "MULT: " << mult << std::endl;
							//std::cout << "COLOR: " << color << std::endl;
						}

						// We cannot end yet
						if (cameraState.mPathLength < mMinPathLength)
							break;

						// Get background light					
						const BackgroundLight* background = mScene.GetBackground();
						if (!background)
							break;

						// In attenuating media the ray can never travel to infinity
						if (mScene.GetGlobalMediumPtr()->HasAttenuation())
							break;

						// Stop if we are in the light sampling mode and could have sampled this light last time in the next event estimation
						if (mAlgorithm == kPTls && cameraState.mPathLength > 1 && !cameraState.mLastSpecular)
							break;

						// Attenuate by intersected media (if any)
						float raySamplePdf(1.0f);
						float raySampleRevPdf(1.0f);
						if (!mVolumeSegments.empty())
						{
							// PDF
							raySamplePdf = VolumeSegment::AccumulatePdf(mVolumeSegments);
							UPBP_ASSERT(raySamplePdf > 0);

							// Reverse PDF
							raySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
							UPBP_ASSERT(raySampleRevPdf > 0);

							// Attenuation
							cameraState.mThroughput *= VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments) / raySamplePdf;
						}

						if (cameraState.mThroughput.isBlackOrNegative())
							break;

						// Update affected MIS data
						{
						const float raySamplePdfInv = 1.0f / raySamplePdf;
						mCameraVerticesMisData[cameraState.mPathLength].mPdfAInv = cameraState.mLastPdfWInv * raySamplePdfInv;
						mCameraVerticesMisData[cameraState.mPathLength].mRevPdfA = 1.0f;
						mCameraVerticesMisData[cameraState.mPathLength].mRaySamplePdfInv = raySamplePdfInv;
						mCameraVerticesMisData[cameraState.mPathLength].mRaySampleRevPdfInv = 1.0f;
						mCameraVerticesMisData[cameraState.mPathLength].mRaySamplePdfsRatio = 0.0f;
						mCameraVerticesMisData[cameraState.mPathLength].mSinTheta = 0.0f;
						mCameraVerticesMisData[cameraState.mPathLength].mCosThetaOut = 0.0f;
						mCameraVerticesMisData[cameraState.mPathLength].mSurfMisWeightFactor = 0.0f;
						mCameraVerticesMisData[cameraState.mPathLength].mPP3DMisWeightFactor = 0.0f;
						mCameraVerticesMisData[cameraState.mPathLength].mPB2DMisWeightFactor = 0.0f;
						mCameraVerticesMisData[cameraState.mPathLength].mBB1DMisWeightFactor = 0.0f;
						mCameraVerticesMisData[cameraState.mPathLength].mBB1DBeamSelectionPdf = 0.0f;
						mCameraVerticesMisData[cameraState.mPathLength].mIsDelta = false;
						mCameraVerticesMisData[cameraState.mPathLength].mIsOnLightSource = true;
						mCameraVerticesMisData[cameraState.mPathLength].mIsSpecular = false;
						mCameraVerticesMisData[cameraState.mPathLength].mInMediumWithBeams = false;
						mCameraVerticesMisData[cameraState.mPathLength - 1].mRevPdfA *= raySampleRevPdf;
						mCameraVerticesMisData[cameraState.mPathLength - 1].mRaySampleRevPdfInv = 1.0f / raySampleRevPdf;
						}
						if (lastMedium && !lastMedium->IsHomogeneous()) // Homogeneous case was solved immediately when processing the vertex for the first time
						{
							float firstSegmentRayOverSampleRevPdf;
							lastMedium->RaySamplePdf(ray, mVolumeSegments.front().mDistMin, mVolumeSegments.front().mDistMax, 0, &firstSegmentRayOverSampleRevPdf);
							const float firstSegmentRayInSampleRevPdf = mVolumeSegments.front().mRaySampleRevPdf; // We were in medium -> we know we have insampled
							mCameraVerticesMisData[cameraState.mPathLength - 1].mRaySampleRevPdfsRatio = firstSegmentRayOverSampleRevPdf / firstSegmentRayInSampleRevPdf;
						}

						mDebugImages.ResetTemp();
						// Accumulate contribution
						color += cameraState.mThroughput *
							GetLightRadiance(mScene.GetBackground(), cameraState, Pos(0));
						const Rgb debugRgb = cameraState.mThroughput * mDebugImages.getTempRGB();
						break;
					}

					UPBP_ASSERT(isect.IsValid());


					////////////////////////////////////////////////////////////////
					// Vertex merging: beam x beam 1D

					if (mMergeWithLightVerticesBB1D && !mPhotonBeamsArray.empty() && !stopBB1D)
					{
						mDebugImages.ResetAccum();
						Rgb contrib(0);
						uint estimatorTechniques = mEstimatorTechniques;
						//if (!cameraState.mSpecularPath) estimatorTechniques |= BEAM_REDUCTION;
						embree::AdditionalRayDataForMis data(&mLightVertices, &mPathEnds, &mCameraVerticesMisData, cameraState.mPathLength, mMinPathLength, mMaxPathLength, BeamType::LONG_BEAM, mPhotonBeamType, cameraState.mLastPdfWInv, 0, 0, 0, mBB1DMisWeightFactor, !mPhotonBeamsArray.empty() ? &Evaluator : NULL, mBB1DMinMFP, mBB1DUsedLightSubPathCount, mMinDistToMed, 0.0f, 0.0f, 0, &mDebugImages);
						if (isect.IsOnSurface())
							contrib = Evaluator.evalBeamBeamEstimate(BeamType::LONG_BEAM, ray, mVolumeSegments, distance, estimatorTechniques, originInMedium ? AbstractMedium::kOriginInMedium : 0, &data);
						else
							contrib = Evaluator.evalBeamBeamEstimate(BeamType::LONG_BEAM, ray, mLiteVolumeSegments, distance, estimatorTechniques, originInMedium ? AbstractMedium::kOriginInMedium : 0, &data);
						const Rgb mult = cameraState.mThroughput * mBB1DNormalization;
						color += mult * contrib;
				/*		std::cout << "BB1 contrib: " << contrib << std::endl;
						std::cout << "MULT: " << mult << std::endl;
						std::cout << "COLOR: " << color << std::endl;*/
						mDebugImages.addAccumulatedLightSample(cameraState.mPathLength, DebugImages::BB1D, screenSample, mult);
					}

					// Attenuate by intersected media (if any)
					float raySamplePdf(1.0f);
					float raySampleRevPdf(1.0f);
					if (!mVolumeSegments.empty())
					{
						// PDF
						raySamplePdf = VolumeSegment::AccumulatePdf(mVolumeSegments);
						UPBP_ASSERT(raySamplePdf > 0);

						// Reverse PDF
						raySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
						UPBP_ASSERT(raySampleRevPdf > 0);

						// Attenuation
						cameraState.mThroughput *= VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments) / raySamplePdf;
					}

					if (cameraState.mThroughput.isBlackOrNegative())
						break;

					// Prepare scattering function at the hitpoint (BSDF/phase depending on whether the hitpoint is at surface or in media, the isect knows)
					BSDF bsdf(ray, isect, mScene, BSDF::kFromCamera, mScene.RelativeIOR(isect, cameraState.mBoundaryStack));

					if (!bsdf.IsValid()) // e.g. hitting surface too parallel with tangent plane
						break;

					// Compute hitpoint
					Pos hitPoint = ray.origin + ray.direction * isect.mDist;

					originInMedium = isect.IsInMedium();
					float speed = mDefaultLightSpeed;

					if (originInMedium) {
						speed /= 1.5; //TODO
					}
					distance = isect.mDist / speed;

					// Update affected MIS data
					{
						const float distSq = Utils::sqr(isect.mDist);
						const float raySamplePdfInv = 1.0f / raySamplePdf;
						mCameraVerticesMisData[cameraState.mPathLength].mPdfAInv = cameraState.mLastPdfWInv * distSq * raySamplePdfInv / std::abs(bsdf.CosThetaFix());
						mCameraVerticesMisData[cameraState.mPathLength].mRevPdfA = 1.0f;
						mCameraVerticesMisData[cameraState.mPathLength].mRaySamplePdfInv = raySamplePdfInv;
						mCameraVerticesMisData[cameraState.mPathLength].mRaySampleRevPdfInv = 1.0f;
						mCameraVerticesMisData[cameraState.mPathLength].mSinTheta = 0.0f;
						mCameraVerticesMisData[cameraState.mPathLength].mCosThetaOut = 0.0f;
						mCameraVerticesMisData[cameraState.mPathLength].mBB1DMisWeightFactor = bsdf.IsOnSurface() ? 0.0f : mBB1DMisWeightFactor;
						mCameraVerticesMisData[cameraState.mPathLength].mBB1DBeamSelectionPdf = bsdf.IsOnSurface() ? 0.0f : ((mMergeWithLightVerticesBB1D && !mPhotonBeamsArray.empty() && Evaluator.sMaxBeamsInCell) ? Evaluator.getBeamSelectionPdf(hitPoint) : 1.0f);
						mCameraVerticesMisData[cameraState.mPathLength].mIsDelta = isect.mLightID >= 0 ? false : bsdf.IsDelta();
						mCameraVerticesMisData[cameraState.mPathLength].mIsOnLightSource = isect.mLightID >= 0;
						mCameraVerticesMisData[cameraState.mPathLength].mIsSpecular = false;
						mCameraVerticesMisData[cameraState.mPathLength].mInMediumWithBeams = bsdf.IsOnSurface() ? false : (bsdf.GetMedium()->GetMeanFreePath(hitPoint) > mBB1DMinMFP);

						mCameraVerticesMisData[cameraState.mPathLength].mRaySamplePdfsRatio = 0.0f;
						mCameraVerticesMisData[cameraState.mPathLength].mRaySampleRevPdfsRatio = 0.0f;
						if (bsdf.IsInMedium())
						{
							if (bsdf.GetMedium()->IsHomogeneous())
							{
								mCameraVerticesMisData[cameraState.mPathLength].mRaySamplePdfsRatio = 1.0f / ((const HomogeneousMedium*)bsdf.GetMedium())->mMinPositiveAttenuationCoefComp();
								mCameraVerticesMisData[cameraState.mPathLength].mRaySampleRevPdfsRatio = mCameraVerticesMisData[cameraState.mPathLength].mRaySamplePdfsRatio;
							}
							else
							{
								const float lastSegmentRayOverSamplePdf = bsdf.GetMedium()->RaySamplePdf(ray, mVolumeSegments.back().mDistMin, mVolumeSegments.back().mDistMax, 0);
								const float lastSegmentRayInSamplePdf = mVolumeSegments.back().mRaySamplePdf; // We are in medium -> we know we have insampled
								mCameraVerticesMisData[cameraState.mPathLength].mRaySamplePdfsRatio = lastSegmentRayOverSamplePdf / lastSegmentRayInSamplePdf;
							}
						}

						// Update reverse PDFs of the previous vertex
						mCameraVerticesMisData[cameraState.mPathLength - 1].mRevPdfA *= raySampleRevPdf / distSq;
						mCameraVerticesMisData[cameraState.mPathLength - 1].mRaySampleRevPdfInv = 1.0f / raySampleRevPdf;

						if (lastMedium && !lastMedium->IsHomogeneous()) // Homogeneous case was solved immediately when processing the vertex for the first time
						{
							float firstSegmentRayOverSampleRevPdf;
							lastMedium->RaySamplePdf(ray, mVolumeSegments.front().mDistMin, mVolumeSegments.front().mDistMax, 0, &firstSegmentRayOverSampleRevPdf);
							const float firstSegmentRayInSampleRevPdf = mVolumeSegments.front().mRaySampleRevPdf; // We were in medium -> we know we have insampled
							mCameraVerticesMisData[cameraState.mPathLength - 1].mRaySampleRevPdfsRatio = firstSegmentRayOverSampleRevPdf / firstSegmentRayInSampleRevPdf;
						}
					}

					// Light source has been hit; terminate afterwards, since
					// our light sources do not have reflective properties
					if (isect.mLightID >= 0)
					{
						// We cannot end yet
						if (cameraState.mPathLength < mMinPathLength)
							break;

						// Stop if we are in the light sampling mode and could have sampled this light last time in the next event estimation
						if (mAlgorithm == kPTls && cameraState.mPathLength > 1 && !cameraState.mLastSpecular)
							break;

						// Get hit light
						const AbstractLight* light = mScene.GetLightPtr(isect.mLightID);
						UPBP_ASSERT(light);

						// Add its contribution
						mDebugImages.ResetTemp();
						const Rgb contrib = cameraState.mThroughput *
							GetLightRadiance(light, cameraState, hitPoint);
						color += contrib;
						/*const Rgb debugRgb = cameraState.mThroughput * mDebugImages.getTempRGB();
						mDebugImages.addSample(cameraState.mPathLength, 0, DebugImages::BPT, screenSample, debugRgb, debugRgb * mDebugImages.getTempMisWeight(), mDebugImages.getTempMisWeight());*/
						break;
					}

					// Terminate if eye sub-path is too long for connections or merging
					if (cameraState.mPathLength >= mMaxPathLength)
						break;

					// Ignore contribution of primary rays from medium too close to camera
					if (cameraState.mPathLength > 1 || bsdf.IsOnSurface() || isect.mDist >= mMinDistToMed)
					{
						////////////////////////////////////////////////////////////////
						// Vertex connection: Connect to a light source
						if (mConnectToLightSource && !bsdf.IsDelta() && cameraState.mPathLength + 1 >= mMinPathLength && mScene.GetLightCount() > 0 && (bsdf.IsInMedium() || !onlySpecSurf))
						{
							color += cameraState.mThroughput *
								DirectIllumination(cameraState, hitPoint, bsdf);
						}

						////////////////////////////////////////////////////////////////
						// Vertex connection: Connect to light vertices
						if (mConnectToLightVertices && !bsdf.IsDelta() && !mLightVertices.empty() && (bsdf.IsInMedium() || !onlySpecSurf))
						{
							// Determine whether the vertex is in medium behind real geometry
							bool behindSurf = false;
							if (bsdf.IsInMedium() && !cameraState.mBoundaryStack.IsEmpty())
							{
								int matId = cameraState.mBoundaryStack.Top().mMaterialId;
								if (matId >= 0)
								{
									const Material& mat = mScene.GetMaterial(matId);
									if (mat.mGeometryType != GeometryType::IMAGINARY)
										behindSurf = true;
								}
							}

							int pathIdxMod = mRng.GetUint() % pathCountL;

							// For VC, each light sub-path is assigned to a particular eye
							// sub-path, as in traditional BPT. It is also possible to
							// connect to vertices from any light path, but MIS should
							// be revisited.
							const Vec2i range(
								(pathIdxMod == 0) ? 0 : mPathEnds[pathIdxMod - 1],
								mPathEnds[pathIdxMod]);

							for (int i = range[0]; i < range[1]; i++)
							{
								const UPBPLightVertex& lightVertex = mLightVertices[i];

								if (lightVertex.mPathLength + 1 +
									cameraState.mPathLength < mMinPathLength)
									continue;

								// Light vertices are stored in increasing path length
								// order; once we go above the max path length, we can
								// skip the rest
								if (lightVertex.mPathLength + 1 +
									cameraState.mPathLength > mMaxPathLength)
									break;

								// We store all light vertices in order to compute MIS weights but not all can be used for VC
								if (!lightVertex.mConnectable)
									continue;

								// Don't try connect vertices in different media with real geometry
								if (lightVertex.mBSDF.IsInMedium() && bsdf.IsInMedium() && lightVertex.mBSDF.GetMedium() != bsdf.GetMedium()
									&& (lightVertex.mBehindSurf || behindSurf))
									continue;

								const Rgb mult = cameraState.mThroughput * lightVertex.mThroughput;
								auto conn = ConnectVertices(lightVertex, bsdf, hitPoint, cameraState);
								color += mult * conn;
								//std::cout << "CONN: " << conn << std::endl;
								//std::cout << "MULT: "<<mult << std::endl;
							}
						}

					}

					// Continue random walk
					if (!SampleScattering(bsdf, hitPoint, isect, cameraState, mCameraVerticesMisData[cameraState.mPathLength], mCameraVerticesMisData[cameraState.mPathLength - 1]))
						break;

					if (bsdf.IsOnSurface())
					{
						if (!cameraState.mLastSpecular)
						{
							if (onlySpecSurf || (mEstimatorTechniques & SPECULAR_ONLY))
								break;

							if (mEstimatorTechniques & BB1D_PREVIOUS)
								stopBB1D = true;
						}

						lastMedium = NULL;
					}
					else
					{
						if (mEstimatorTechniques & SPECULAR_ONLY)
							break;

						if (onlySpecSurf)
						{
							if (mEstimatorTechniques & COMPATIBLE)
								onlySpecSurf = false;
							else
								break;
						}

						if (mEstimatorTechniques & BB1D_PREVIOUS)
							stopBB1D = true;

						lastMedium = bsdf.GetMedium();
					}
				}
				//if (color.isPositive()) {
				//	std::cout << "color: " << color << std::endl;
				//}
				mFramebuffer.AddColor(screenSample, color);
			}

		mTimer.Stop();
		if (mVerbose)
			std::cout << std::setprecision(3) << "   - camera sub-path tracing done in " << mTimer.GetLastElapsedTime() << " sec. " << std::endl;

		mCameraTracingTime += mTimer.GetLastElapsedTime();
		// Delete stored photon beams
		if (mMergeWithLightVerticesBB1D && mMaxPathLength > 1 && !mPhotonBeamsArray.empty())
		{
			Evaluator.destroy();
		}

		mIterations++;
	}

private:

	//////////////////////////////////////////////////////////////////////////
	// Camera tracing methods
	//////////////////////////////////////////////////////////////////////////

	// Generates new camera sample given a pixel index
	Vec2f GenerateCameraSample(
		const int    aPixelIndex,
		SubPathState& oCameraState)
	{
		const Camera& camera = mScene.mCamera;
		const int resX = int(camera.mResolution.get(0));
		const int resY = int(camera.mResolution.get(1));

		// Determine pixel (x, y)
		const int x = aPixelIndex % resX;
		const int y = aPixelIndex / resX;

		// Jitter pixel position
		const Vec2f sample = Vec2f(float(x), float(y)) + mRng.GetVec2f();

		// Generate ray
		const Ray primaryRay = camera.GenerateRay(sample);

		// Compute PDF conversion factor from area on image plane to solid angle on ray
		const float cosAtCamera = dot(camera.mDirection, primaryRay.direction);
		const float imagePointToCameraDist = camera.mImagePlaneDist / cosAtCamera;
		const float imageToSolidAngleFactor = Utils::sqr(imagePointToCameraDist) / cosAtCamera;

		// We put the virtual image plane at such a distance from the camera origin
		// that the pixel area is one and thus the image plane sampling PDF is 1.
		// The solid angle ray PDF is then equal to the conversion factor from
		// image plane area density to ray solid angle density
		const float cameraPdfW = imageToSolidAngleFactor;

		oCameraState.mOrigin = primaryRay.origin;
		oCameraState.mDirection = primaryRay.direction;
		oCameraState.mThroughput = Rgb(1);
		oCameraState.mPathLength = 1;
		oCameraState.mSpecularPath = 1;
		oCameraState.mLastSpecular = true;
		oCameraState.mLastPdfWInv = mScreenPixelCount / cameraPdfW;

		// Init the boundary stack with the global medium and add enclosing material and medium if present
		mScene.InitBoundaryStack(oCameraState.mBoundaryStack);
		if (camera.mMatID != -1 && camera.mMedID != -1) mScene.AddToBoundaryStack(camera.mMatID, camera.mMedID, oCameraState.mBoundaryStack);

		return sample;
	}

	// Returns the radiance of a light source when hit by a random ray,
	// multiplied by MIS weight. Can be used for both Background and Area lights.
	Rgb GetLightRadiance(
		const AbstractLight* aLight,
		const SubPathState& aCameraState,
		const Pos& aHitpoint) const
	{
		if (aCameraState.mSpecularPath == 1 && mIgnoreFullySpecPaths)
			return Rgb(0);
		// We sample lights uniformly
		const int   lightCount = mScene.GetLightCount();
		const float lightPickProb = 1.f / lightCount;

		float directPdfA, emissionPdfW;
		const Rgb radiance = aLight->GetRadiance(mScene.mSceneSphere,
			aCameraState.mDirection, aHitpoint, &directPdfA, &emissionPdfW);

		if (radiance.isBlackOrNegative())
			return Rgb(0);

		// If we see light source directly from camera, no weighting is required
		if (aCameraState.mPathLength == 1)
		{
			mDebugImages.setTempRgbWeight(radiance, 1.0f);
			return radiance;
		}

		// When using only vertex merging, we want purely specular paths
		// to give radiance (cannot get it otherwise). Rest is handled
		// by merging and we should return 0.
		if (mEstimatorTechniques && !(mEstimatorTechniques & BPT))
			return aCameraState.mSpecularPath ? radiance : Rgb(0);

		directPdfA *= lightPickProb;
		emissionPdfW *= lightPickProb;

		UPBP_ASSERT(directPdfA > 0);
		UPBP_ASSERT(emissionPdfW > 0);

		// MIS weight
		float misWeight = 1.f;
		if (mConnectToLightVertices)
		{
			UPBP_ASSERT(directPdfA > 0);
			const float wCamera = AccumulateCameraPathWeight2(aCameraState.mPathLength, directPdfA, 0, 0, 0, emissionPdfW / directPdfA);
			misWeight = 1.0f / (wCamera + 1.f);
		}
		else if (mAlgorithm == kPTmis && !aCameraState.mLastSpecular)
		{
			const float wCamera = directPdfA * mCameraVerticesMisData[aCameraState.mPathLength].mPdfAInv;
			misWeight = 1.0f / (wCamera + 1.f);
		}

		mDebugImages.setTempRgbWeight(radiance, misWeight);
		return misWeight * radiance;
	}

	// Connects camera vertex to randomly chosen light point.
	// Returns emitted radiance multiplied by path MIS weight.
	// Has to be called AFTER updating the MIS quantities.
	Rgb DirectIllumination(
		const SubPathState& aCameraState,
		const Pos& aHitpoint,
		const BSDF& aCameraBSDF)
	{
		// We sample lights uniformly
		const int   lightCount = mScene.GetLightCount();
		const float lightPickProb = 1.f / lightCount;

		const int   lightID = int(mRng.GetFloat() * lightCount);
		const Vec2f rndPosSamples = mRng.GetVec2f();

		const AbstractLight* light = mScene.GetLightPtr(lightID);
		UPBP_ASSERT(light);

		// Light in infinity in attenuating homogeneous global medium is always reduced to zero
		if (!light->IsFinite() && mScene.GetGlobalMediumPtr()->HasAttenuation())
			return Rgb(0);

		Dir directionToLight;
		float distance;
		float directPdfW, emissionPdfW, cosAtLight;
		const Rgb radiance = light->Illuminate(mScene.mSceneSphere, aHitpoint,
			rndPosSamples, directionToLight, distance, directPdfW,
			&emissionPdfW, &cosAtLight);

		// If radiance == 0, other values are undefined, so shave to early exit
		if (radiance.isBlackOrNegative())
			return Rgb(0);

		UPBP_ASSERT(directPdfW > 0);
		UPBP_ASSERT(emissionPdfW > 0);
		UPBP_ASSERT(cosAtLight > 0);

		// Get BSDF factor at the last camera vertex
		float bsdfDirPdfW, bsdfRevPdfW, cosToLight, sinTheta;
		Rgb bsdfFactor = aCameraBSDF.Evaluate(directionToLight, cosToLight, &bsdfDirPdfW, &bsdfRevPdfW, &sinTheta);

		if (bsdfFactor.isBlackOrNegative())
			return Rgb(0);

		const float continuationProbability = aCameraBSDF.ContinuationProb();

		// If the light is delta light, we can never hit it
		// by BSDF sampling, so the probability of this path is 0
		bsdfDirPdfW *= light->IsDelta() ? 0.f : continuationProbability;
		bsdfRevPdfW *= continuationProbability;

		UPBP_ASSERT(bsdfRevPdfW > 0);
		UPBP_ASSERT(cosToLight > 0);

		Rgb contrib(0);

		// Test occlusion
		mVolumeSegments.clear();
		if (!mScene.Occluded(aHitpoint, directionToLight, distance, aCameraState.mBoundaryStack, aCameraBSDF.IsInMedium() ? AbstractMedium::kOriginInMedium : 0, mVolumeSegments))
		{
			// Get attenuation from intersected media (if any)
			float nextRaySamplePdf(1.0f);
			float nextRaySampleRevPdf(1.0f);
			Rgb nextAttenuation(1.0f);
			if (!mVolumeSegments.empty())
			{
				// PDF
				nextRaySamplePdf = VolumeSegment::AccumulatePdf(mVolumeSegments);
				UPBP_ASSERT(nextRaySamplePdf > 0);

				// Reverse PDF
				nextRaySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
				UPBP_ASSERT(nextRaySampleRevPdf > 0);

				// Attenuation (without PDF!)
				nextAttenuation = VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments);
				if (!nextAttenuation.isPositive())
					return Rgb(0);
			}

			// MIS weight
			float misWeight = 1.f;
			if (mConnectToLightVertices)
			{
				float lastSinTheta = 0;
				float lastRaySampleRevPdfInv = 0;
				float lastRaySampleRevPdfsRatio = 0;
				if (aCameraBSDF.IsInMedium())
				{
					lastSinTheta = sinTheta;
					lastRaySampleRevPdfInv = 1.0f / nextRaySampleRevPdf;
					lastRaySampleRevPdfsRatio = mCameraVerticesMisData[aCameraState.mPathLength].mRaySamplePdfsRatio;
					if (!aCameraBSDF.GetMedium()->IsHomogeneous())
					{
						float firstSegmentRayOverSampleRevPdf;
						aCameraBSDF.GetMedium()->RaySamplePdf(Ray(aCameraState.mOrigin, aCameraState.mDirection), mVolumeSegments.front().mDistMin, mVolumeSegments.front().mDistMax, 0, &firstSegmentRayOverSampleRevPdf);
						const float firstSegmentRayInSampleRevPdf = mVolumeSegments.front().mRaySampleRevPdf; // We are in medium -> we know we have insampled
						lastRaySampleRevPdfsRatio = firstSegmentRayOverSampleRevPdf / firstSegmentRayInSampleRevPdf;
					}
				}

				// For wCamera we need ratio = emissionPdfA / directPdfA,
				// with emissionPdfA being the product of the PDFs for choosing the
				// point on the light source and sampling the outgoing direction.
				// What we are given by the light source instead are emissionPdfW
				// and directPdfW. Converting to area PDFs and plugging into ratio:
				//    emissionPdfA = emissionPdfW * cosToLight / dist^2
				//    directPdfA   = directPdfW * cosAtLight / dist^2
				//    ratio = (emissionPdfW * cosToLight / dist^2) / (directPdfW * cosAtLight / dist^2)
				//    ratio = (emissionPdfW * cosToLight) / (directPdfW * cosAtLight)
				// Also note that both emissionPdfW and directPdfW should be
				// multiplied by lightPickProb, so it cancels out.
				UPBP_ASSERT(nextRaySampleRevPdf * emissionPdfW * cosToLight / (directPdfW * cosAtLight) > 0);
				const float wCamera = AccumulateCameraPathWeight2(aCameraState.mPathLength, nextRaySampleRevPdf * emissionPdfW * cosToLight / (directPdfW * cosAtLight), lastSinTheta, lastRaySampleRevPdfInv, lastRaySampleRevPdfsRatio, bsdfRevPdfW);

				// Note that wLight is a ratio of area PDFs. But since both are on the
				// light source, their distance^2 and cosine terms cancel out.
				// Therefore we can write wLight as a ratio of solid angle PDFs,
				// both expressed w.r.t. the same shading point.
				const float wLight = light->IsDelta() ? 0 : (nextRaySamplePdf * bsdfDirPdfW) / (directPdfW * lightPickProb);
				misWeight = 1.0f / (wCamera + 1.f + wLight);
			}
			else if (mAlgorithm != kPTls && !light->IsDelta())
				misWeight = Mis2(lightPickProb * directPdfW, bsdfDirPdfW * nextRaySamplePdf);

			contrib = (cosToLight / (lightPickProb * directPdfW)) * (radiance * nextAttenuation * bsdfFactor);
			mDebugImages.setTempRgbWeight(contrib, misWeight);
			contrib *= misWeight;
		}

		if (contrib.isBlackOrNegative())
		{
			mDebugImages.ResetTemp();
			return Rgb(0);
		}

		return contrib;
	}

	// Connects an eye and a light vertex. Result multiplied by MIS weight, but
	// not multiplied by vertex throughputs. Has to be called AFTER updating MIS
	// constants. 'direction' is FROM eye TO light vertex.
	Rgb ConnectVertices(
		const UPBPLightVertex& aLightVertex,
		const BSDF& aCameraBSDF,
		const Pos& aCameraHitpoint,
		const SubPathState& aCameraState)
	{
		// Get the connection
		Dir direction = aLightVertex.mHitpoint - aCameraHitpoint;
		const float dist2 = direction.square();
		float  distance = std::sqrt(dist2);
		direction /= distance;

		// Evaluate BSDF at camera vertex
		float cosCamera, cameraBsdfDirPdfW, cameraBsdfRevPdfW, sinThetaCamera;
		Rgb cameraBsdfFactor = aCameraBSDF.Evaluate(
			direction, cosCamera, &cameraBsdfDirPdfW,
			&cameraBsdfRevPdfW, &sinThetaCamera);

		if (cameraBsdfFactor.isBlackOrNegative())
			return Rgb(0);

		// Camera continuation probability (for Russian roulette)
		const float cameraCont = aCameraBSDF.ContinuationProb();
		cameraBsdfDirPdfW *= cameraCont;
		cameraBsdfRevPdfW *= cameraCont;
		UPBP_ASSERT(cameraBsdfDirPdfW > 0);
		UPBP_ASSERT(cameraBsdfRevPdfW > 0);

		// Evaluate BSDF at light vertex
		float cosLight, lightBsdfDirPdfW, lightBsdfRevPdfW, sinThetaLight;
		const Rgb lightBsdfFactor = aLightVertex.mBSDF.Evaluate(
			-direction, cosLight, &lightBsdfDirPdfW,
			&lightBsdfRevPdfW, &sinThetaLight);

		if (lightBsdfFactor.isBlackOrNegative())
			return Rgb(0);

		// Light continuation probability (for Russian roulette)
		const float lightCont = aLightVertex.mBSDF.ContinuationProb();
		lightBsdfDirPdfW *= lightCont;
		lightBsdfRevPdfW *= lightCont;
		UPBP_ASSERT(lightBsdfDirPdfW > 0);
		UPBP_ASSERT(lightBsdfRevPdfW > 0);

		// Compute geometry term
		const float geometryTerm = cosLight * cosCamera / dist2;
		if (geometryTerm < 0)
			return Rgb(0);

		// Convert PDFs to area PDF
		const float cameraBsdfDirPdfA = PdfWtoA(cameraBsdfDirPdfW, distance, cosLight);
		const float lightBsdfDirPdfA = PdfWtoA(lightBsdfDirPdfW, distance, cosCamera);
		UPBP_ASSERT(cameraBsdfDirPdfA > 0);
		UPBP_ASSERT(lightBsdfDirPdfA > 0);

		uint raySamplingFlags = 0;
		if (aCameraBSDF.IsInMedium()) raySamplingFlags |= AbstractMedium::kOriginInMedium;
		if (aLightVertex.mInMedium)   raySamplingFlags |= AbstractMedium::kEndInMedium;

		// Test occlusion
		mVolumeSegments.clear();
		if (mScene.Occluded(aCameraHitpoint, direction, distance, aCameraState.mBoundaryStack, raySamplingFlags, mVolumeSegments))
			return Rgb(0);

		// Attenuate by intersected media (if any)
		float raySamplePdf(1.0f);
		float raySampleRevPdf(1.0f);
		Rgb mediaAttenuation(1.0f);
		if (!mVolumeSegments.empty())
		{
			// PDF
			raySamplePdf = VolumeSegment::AccumulatePdf(mVolumeSegments);
			UPBP_ASSERT(raySamplePdf > 0);

			// Reverse PDF
			raySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
			UPBP_ASSERT(raySampleRevPdf > 0);

			// Attenuation (without PDF!)
			mediaAttenuation = VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments);
			if (!mediaAttenuation.isPositive())
				return Rgb(0);
		}

		// MIS weight

		// Camera part
		float lastSinThetaCamera = 0;
		float lastRaySampleRevPdfInvCamera = 0;
		float lastRaySampleRevPdfsRatioCamera = 0;
		if (aCameraBSDF.IsInMedium())
		{
			lastSinThetaCamera = sinThetaCamera;
			lastRaySampleRevPdfInvCamera = 1.0f / raySampleRevPdf;
			lastRaySampleRevPdfsRatioCamera = mCameraVerticesMisData[aCameraState.mPathLength].mRaySamplePdfsRatio;
			if (!aCameraBSDF.GetMedium()->IsHomogeneous())
			{
				float firstSegmentRayOverSampleRevPdf;
				aCameraBSDF.GetMedium()->RaySamplePdf(Ray(aCameraState.mOrigin, aCameraState.mDirection), mVolumeSegments.front().mDistMin, mVolumeSegments.front().mDistMax, 0, &firstSegmentRayOverSampleRevPdf);
				const float firstSegmentRayInSampleRevPdf = mVolumeSegments.front().mRaySampleRevPdf; // We are in medium -> we know we have insampled
				lastRaySampleRevPdfsRatioCamera = firstSegmentRayOverSampleRevPdf / firstSegmentRayInSampleRevPdf;
			}
		}
		UPBP_ASSERT(raySampleRevPdf * lightBsdfDirPdfA > 0);
		const float wCamera = AccumulateCameraPathWeight2(aCameraState.mPathLength, raySampleRevPdf * lightBsdfDirPdfA, lastSinThetaCamera, lastRaySampleRevPdfInvCamera, lastRaySampleRevPdfsRatioCamera, cameraBsdfRevPdfW);

		// Light part
		float lastSinThetaLight = 0;
		float lastRaySampleRevPdfInvLight = 0;
		float lastRaySampleRevPdfsRatioLight = 0;
		if (aLightVertex.mInMedium)
		{
			lastSinThetaLight = sinThetaLight;
			lastRaySampleRevPdfInvLight = 1.0f / raySamplePdf;
			lastRaySampleRevPdfsRatioLight = aLightVertex.mMisData.mRaySamplePdfsRatio;
			if (!aLightVertex.mBSDF.GetMedium()->IsHomogeneous())
			{
				const float lastSegmentRayOverSamplePdf = aLightVertex.mBSDF.GetMedium()->RaySamplePdf(Ray(aCameraState.mOrigin, aCameraState.mDirection), mVolumeSegments.back().mDistMin, mVolumeSegments.back().mDistMax, 0);
				const float lastSegmentRayInSamplePdf = mVolumeSegments.back().mRaySamplePdf; // We are in medium -> we know we have insampled
				lastRaySampleRevPdfsRatioLight = lastSegmentRayOverSamplePdf / lastSegmentRayInSamplePdf;
			}
		}
		UPBP_ASSERT(raySamplePdf * cameraBsdfDirPdfA > 0);
		const float wLight = AccumulateLightPathWeight2(aLightVertex.mPathIdx, aLightVertex.mPathLength, raySamplePdf * cameraBsdfDirPdfA, lastSinThetaLight, lastRaySampleRevPdfInvLight, lastRaySampleRevPdfsRatioLight, lightBsdfRevPdfW, BPT, false);
		const float misWeight = 1.f / (wCamera + 1.f + wLight);

		Rgb contrib = (geometryTerm)*cameraBsdfFactor * lightBsdfFactor * mediaAttenuation;
		mDebugImages.setTempRgbWeight(contrib, misWeight);
		contrib *= misWeight;

		if (contrib.isBlackOrNegative())
		{
			mDebugImages.ResetTemp();
			return Rgb(0);
		}

		return contrib;
	}

	// Accumulates PDF ratios of all sampling techniques along path originally sampled from camera
	inline float AccumulateCameraPathWeight2(
		const int   aPathLength,
		const float aLastRevPdfA,
		const float aLastSinTheta,
		const float aLastRaySampleRevPdfInv,
		const float aLastRaySampleRevPdfsRatio,
		const float aNextToLastPartialRevPdfW) const
	{
		return AccumulateCameraPathWeight(aPathLength, aLastRevPdfA, aLastSinTheta, aLastRaySampleRevPdfInv, aLastRaySampleRevPdfsRatio, aNextToLastPartialRevPdfW, BeamType::LONG_BEAM, mPhotonBeamType, mEstimatorTechniques, mCameraVerticesMisData);
	}

	//////////////////////////////////////////////////////////////////////////
	// Light tracing methods
	//////////////////////////////////////////////////////////////////////////

	// Samples light emission
	void GenerateLightSample(int aPathIdx, SubPathState& oLightState)
	{
		// We sample lights uniformly
		const int   lightCount = mScene.GetLightCount();
		const float lightPickProb = 1.f / lightCount;

		const int   lightID = int(mRng.GetFloat() * lightCount);
		const Vec2f rndDirSamples = mRng.GetVec2f();
		const Vec2f rndPosSamples = mRng.GetVec2f();

		const AbstractLight* light = mScene.GetLightPtr(lightID);
		UPBP_ASSERT(light);

		float emissionPdfW, directPdfA, cosLight;
		oLightState.mThroughput = light->Emit(mScene.mSceneSphere, rndDirSamples, rndPosSamples,
			oLightState.mOrigin, oLightState.mDirection,
			emissionPdfW, &directPdfA, &cosLight);

		emissionPdfW *= lightPickProb;
		directPdfA *= lightPickProb;

		UPBP_ASSERT(emissionPdfW);
		UPBP_ASSERT(directPdfA);

		// Store vertex

		UPBPLightVertex lightVertex;
		lightVertex.mHitpoint = oLightState.mOrigin;
		lightVertex.mThroughput = Rgb(1.0f);
		lightVertex.mPathLength = 0;
		lightVertex.mPathIdx = aPathIdx;
		lightVertex.mInMedium = false;
		lightVertex.mConnectable = false;
		lightVertex.mIsFinite = light->IsFinite();

		lightVertex.mMisData.mPdfAInv = 1.0f / directPdfA;
		lightVertex.mMisData.mRevPdfA = light->IsDelta() ? 0.0f : (light->IsFinite() ? cosLight : 1.f);
		lightVertex.mMisData.mRevPdfAWithoutBsdf = lightVertex.mMisData.mRevPdfA;
		lightVertex.mMisData.mRaySamplePdfInv = 0.0f;
		lightVertex.mMisData.mRaySampleRevPdfInv = 1.0f;
		lightVertex.mMisData.mRaySamplePdfsRatio = 0.0f;
		lightVertex.mMisData.mRaySampleRevPdfsRatio = 0.0f;
		lightVertex.mMisData.mSinTheta = 0.0f;
		lightVertex.mMisData.mCosThetaOut = (!light->IsDelta() && light->IsFinite()) ? cosLight : 1.f;
		lightVertex.mMisData.mSurfMisWeightFactor = 0.0f;
		lightVertex.mMisData.mPP3DMisWeightFactor = 0.0f;
		lightVertex.mMisData.mPB2DMisWeightFactor = 0.0f;
		lightVertex.mMisData.mBB1DMisWeightFactor = 0.0f;
		lightVertex.mMisData.mBB1DBeamSelectionPdf = 0.0f;
		lightVertex.mMisData.mIsDelta = light->IsDelta();
		lightVertex.mMisData.mIsOnLightSource = true;
		lightVertex.mMisData.mIsSpecular = false;
		lightVertex.mMisData.mInMediumWithBeams = false;

		mLightVerticesOnSurfaceCount++;
		mLightVertices.push_back(lightVertex);

		// Complete light path state initialization

		oLightState.mThroughput /= emissionPdfW;
		oLightState.mPathLength = 1;
		oLightState.mIsFiniteLight = light->IsFinite() ? 1 : 0;
		oLightState.mLastSpecular = false;
		oLightState.mLastPdfWInv = directPdfA / emissionPdfW;

		// Init the boundary stack with the global medium and add enclosing material and medium if present
		mScene.InitBoundaryStack(oLightState.mBoundaryStack);
		if (light->mMatID != -1 && light->mMedID != -1) mScene.AddToBoundaryStack(light->mMatID, light->mMedID, oLightState.mBoundaryStack);
	}

	// Computes contribution of light sample to camera by splatting is onto the
	// framebuffer. Multiplies by throughput (obviously, as nothing is returned).
	void ConnectToCamera(
		const int          aLightPathIdx,
		const SubPathState& aLightState,
		const Pos& aHitpoint,
		const BSDF& aLightBSDF,
		const float        aRaySampleRevPdfsRatio)
	{
		// Get camera and direction to it
		const Camera& camera = mScene.mCamera;
		Dir directionToCamera = camera.mOrigin - aHitpoint;

		// Check point is in front of camera
		if (dot(camera.mDirection, -directionToCamera) <= 0.f)
			return;

		// Check it projects to the screen (and where)
		const Vec2f imagePos = camera.WorldToRaster(aHitpoint);
		if (!camera.CheckRaster(imagePos))
			return;

		// Compute distance and normalize direction to camera
		const float distEye2 = directionToCamera.square();
		const float distance = std::sqrt(distEye2);
		directionToCamera /= distance;

		// Ignore contribution of primary rays from medium too close to camera
		if (aLightBSDF.IsInMedium() && distance < mMinDistToMed)
			return;

		// Get the BSDF factor
		float cosToCamera, bsdfDirPdfW, bsdfRevPdfW, sinTheta;
		Rgb bsdfFactor = aLightBSDF.Evaluate(directionToCamera, cosToCamera, &bsdfDirPdfW, &bsdfRevPdfW, &sinTheta);

		if (bsdfFactor.isBlackOrNegative())
			return;

		bsdfRevPdfW *= aLightBSDF.ContinuationProb();

		UPBP_ASSERT(bsdfDirPdfW > 0);
		UPBP_ASSERT(bsdfRevPdfW > 0);
		UPBP_ASSERT(cosToCamera > 0);

		// Compute PDF conversion factor from image plane area to surface area
		const float cosAtCamera = dot(camera.mDirection, -directionToCamera);
		const float imagePointToCameraDist = camera.mImagePlaneDist / cosAtCamera;
		const float imageToSolidAngleFactor = Utils::sqr(imagePointToCameraDist) / cosAtCamera;
		const float imageToSurfaceFactor = imageToSolidAngleFactor * std::abs(cosToCamera) / Utils::sqr(distance);

		// We put the virtual image plane at such a distance from the camera origin
		// that the pixel area is one and thus the image plane sampling PDF is 1.
		// The area PDF of aHitpoint as sampled from the camera is then equal to
		// the conversion factor from image plane area density to surface area density
		const float cameraPdfA = imageToSurfaceFactor;
		UPBP_ASSERT(cameraPdfA > 0);

		const float surfaceToImageFactor = 1.f / imageToSurfaceFactor;

		// Test occlusion
		mVolumeSegments.clear();
		if (!mScene.Occluded(aHitpoint, directionToCamera, distance, aLightState.mBoundaryStack, aLightBSDF.IsInMedium() ? AbstractMedium::kOriginInMedium : 0, mVolumeSegments))
		{
			// Get attenuation from intersected media (if any)
			float raySampleRevPdf(1.0f);
			Rgb mediaAttenuation(1.0f);
			if (!mVolumeSegments.empty())
			{
				// Reverse PDF
				raySampleRevPdf = VolumeSegment::AccumulateRevPdf(mVolumeSegments);
				UPBP_ASSERT(raySampleRevPdf > 0);

				// Attenuation (without PDF!)
				mediaAttenuation = VolumeSegment::AccumulateAttenuationWithoutPdf(mVolumeSegments);
				if (!mediaAttenuation.isPositive())
					return;
			}

			// Compute MIS weight if not doing LT
			float misWeight = 1.f;
			if (mAlgorithm != kLT)
			{
				float lastSinTheta = 0;
				float lastRaySampleRevPdfInv = 0;
				float lastRaySampleRevPdfsRatio = 0;
				if (aLightBSDF.IsInMedium())
				{
					lastSinTheta = sinTheta;
					lastRaySampleRevPdfInv = 1.0f / raySampleRevPdf;
					lastRaySampleRevPdfsRatio = aRaySampleRevPdfsRatio;
					if (!aLightBSDF.GetMedium()->IsHomogeneous())
					{
						float firstSegmentRayOverSampleRevPdf;
						aLightBSDF.GetMedium()->RaySamplePdf(Ray(aLightState.mOrigin, aLightState.mDirection), mVolumeSegments.front().mDistMin, mVolumeSegments.front().mDistMax, 0, &firstSegmentRayOverSampleRevPdf);
						const float firstSegmentRayInSampleRevPdf = mVolumeSegments.front().mRaySampleRevPdf; // We are in medium -> we know we have insampled
						lastRaySampleRevPdfsRatio = firstSegmentRayOverSampleRevPdf / firstSegmentRayInSampleRevPdf;
					}
				}
				UPBP_ASSERT(raySampleRevPdf * cameraPdfA > 0);
				const float wLight = AccumulateLightPathWeight2(aLightPathIdx, aLightState.mPathLength, raySampleRevPdf * cameraPdfA, lastSinTheta, lastRaySampleRevPdfInv, lastRaySampleRevPdfsRatio, bsdfRevPdfW, BPT, true) / mScreenPixelCount;
				misWeight = 1.0f / (1.f + wLight);
			}

			// We divide the contribution by surfaceToImageFactor to convert the (already
			// divided) PDF from surface area to image plane area, w.r.t. which the
			// pixel integral is actually defined. We also divide by the number of samples
			// this technique makes, which is equal to the number of light sub-paths
			Rgb contrib = aLightState.mThroughput * bsdfFactor * mediaAttenuation / (mLightSubPathCount * surfaceToImageFactor);

			if (contrib.isBlackOrNegative())
				return;

			mDebugImages.addSample(0, aLightState.mPathLength + 1, DebugImages::BPT, imagePos, contrib, contrib * misWeight, misWeight);

			contrib *= misWeight;

			mFramebuffer.AddColor(imagePos, contrib);
		}
	}

	// Adds beams to beams array
	void AddBeams(
		const Ray& aRay,
		const Rgb& aThroughput,
		UPBPLightVertex* aLightVertex,
		const uint aRaySamplingFlags,
		const float aLastPdfWInv
	)
	{
		UPBP_ASSERT(aRaySamplingFlags == 0 || aRaySamplingFlags == AbstractMedium::kOriginInMedium);
		UPBP_ASSERT(aLightVertex);

		Rgb throughput = aThroughput;
		float raySamplePdf = 1.0f;
		float raySampleRevPdf = 1.0f;


		UPBP_ASSERT(mPhotonBeamType == LONG_BEAM);
		for (LiteVolumeSegments::const_iterator it = mLiteVolumeSegments.cbegin(); it != mLiteVolumeSegments.cend(); ++it)
		{
			UPBP_ASSERT(it->mMediumID >= 0);
			PTPBBeam beam;
			beam.mMedium = mScene.mMedia[it->mMediumID];
			if (beam.mMedium->HasScattering() && (beam.mMedium->GetMeanFreePath(aRay.origin) > mBB1DMinMFP))
			{
				beam.mRay = Ray(aRay.origin + aRay.direction * it->mDistMin, aRay.direction);
				beam.mLength = it->mDistMax - it->mDistMin;
				beam.mFlags = LONG_BEAM;
				beam.mRaySamplePdf = raySamplePdf;
				beam.mRaySampleRevPdf = raySampleRevPdf;
				beam.mRaySamplingFlags = AbstractMedium::kEndInMedium;
				if (it == mLiteVolumeSegments.cbegin())
					beam.mRaySamplingFlags |= aRaySamplingFlags;
				beam.mLastPdfWInv = aLastPdfWInv;
				beam.mThroughputAtOrigin = throughput;
				beam.mLightVertex = aLightVertex;

				UPBP_ASSERT(mPhotonBeamsArray.size() < mPhotonBeamsArray.capacity());
				mPhotonBeamsArray.push_back(beam);

			}
			if (beam.mMedium->IsHomogeneous())
			{
				const HomogeneousMedium* medium = ((const HomogeneousMedium*)beam.mMedium);
				throughput *= medium->EvalAttenuation(it->mDistMax - it->mDistMin);
			}
			else
			{
				throughput *= beam.mMedium->EvalAttenuation(aRay, it->mDistMin, it->mDistMax);
			}
			float segmentRaySampleRevPdf;
			float segmentRaySamplePdf = beam.mMedium->RaySamplePdf(aRay, it->mDistMin, it->mDistMax, it == mLiteVolumeSegments.cbegin() ? aRaySamplingFlags : 0, &segmentRaySampleRevPdf);
			raySamplePdf *= segmentRaySamplePdf;
			raySampleRevPdf *= segmentRaySampleRevPdf;
		}

		if (!mPhotonBeamsArray.empty() && mPhotonBeamsArray.back().mLength > mPhotonBeamsArray.back().mMedium->MaxBeamLength())
			mPhotonBeamsArray.back().mLength = mPhotonBeamsArray.back().mMedium->MaxBeamLength();
	}

	// Accumulates PDF ratios of all sampling techniques along path originally sampled from light
	inline float AccumulateLightPathWeight2(
		const int   aPathIndex,
		const int   aPathLength,
		const float aLastRevPdfA,
		const float aLastSinTheta,
		const float aLastRaySampleRevPdfInv,
		const float aLastRaySampleRevPdfsRatio,
		const float aNextToLastPartialRevPdfW,
		const uint  aCurrentlyEvaluatedTechnique,
		const bool  aCameraConnection) const
	{
		return AccumulateLightPathWeight(aPathIndex, aPathLength, aLastRevPdfA, aLastSinTheta, aLastRaySampleRevPdfInv, aLastRaySampleRevPdfsRatio, aNextToLastPartialRevPdfW, aCurrentlyEvaluatedTechnique, BeamType::LONG_BEAM, mPhotonBeamType, mEstimatorTechniques, aCameraConnection, &mPathEnds, &mLightVertices);
	}

	//////////////////////////////////////////////////////////////////////////
	// Common methods
	//////////////////////////////////////////////////////////////////////////

	// MIS power, we use balance heuristic
	float Mis(float aPdf) const
	{
		//return std::pow(aPdf, /*power*/);
		return aPdf;
	}

	// MIS weight for 2 PDFs
	float Mis2(
		float aSamplePdf,
		float aOtherPdf) const
	{
		return Mis(aSamplePdf) / (Mis(aSamplePdf) + Mis(aOtherPdf));
	}

	// Samples a scattering direction camera/light sample according to BSDF.
	// Returns false for termination
	bool SampleScattering(
		const BSDF& aBSDF,
		const Pos& aHitPoint,
		const Isect& aIsect,
		SubPathState& aoState,
		MisData& aoCurrentMisData,
		MisData& aoPreviousMisData)
	{
		// Sample scattering function		

		Dir   rndTriplet = mRng.GetVec3f(); // x,y for direction, z for component. No rescaling happens
		float bsdfDirPdfW, cosThetaOut, sinTheta;
		uint  sampledEvent;

		Rgb bsdfFactor = aBSDF.Sample(rndTriplet, aoState.mDirection,
			bsdfDirPdfW, cosThetaOut, &sampledEvent, &sinTheta);

		if (bsdfFactor.isBlackOrNegative())
			return false;

		bool specular = (sampledEvent & BSDF::kSpecular) != 0;

		// If we sampled specular event, then the reverse probability
		// cannot be evaluated, but we know it is exactly the same as
		// forward probability, so just set it. If non-specular event happened,
		// we evaluate the PDF
		float bsdfRevPdfW = bsdfDirPdfW;
		if (!specular)
			bsdfRevPdfW = aBSDF.Pdf(aoState.mDirection, BSDF::kReverse);

		//UPBP_ASSERT(bsdfDirPdfW);
		//UPBP_ASSERT(bsdfRevPdfW);

		// Russian roulette
		const float contProb = aBSDF.ContinuationProb();
		if (contProb == 0 || (contProb < 1.0f && mRng.GetFloat() > contProb))
			return false;

		bsdfDirPdfW *= contProb;
		bsdfRevPdfW *= contProb;

		const float bsdfDirPdfWInv = 1.0f / bsdfDirPdfW;

		// Update path state

		aoState.mOrigin = aHitPoint;
		aoState.mThroughput *= bsdfFactor * (cosThetaOut * bsdfDirPdfWInv);
		aoState.mSpecularPath &= specular ? 1 : 0;
		aoState.mLastPdfWInv = bsdfDirPdfWInv;
		aoState.mLastSpecular = specular;

		// Switch medium on refraction
		if ((sampledEvent & BSDF::kRefract) != 0)
			mScene.UpdateBoundaryStackOnRefract(aIsect, aoState.mBoundaryStack);

		// Update affected MIS data
		aoCurrentMisData.mRevPdfA *= cosThetaOut;
		aoCurrentMisData.mRevPdfAWithoutBsdf = aoCurrentMisData.mRevPdfA;
		aoCurrentMisData.mIsSpecular = specular;
		aoCurrentMisData.mSinTheta = sinTheta;
		aoCurrentMisData.mCosThetaOut = cosThetaOut;
		aoPreviousMisData.mRevPdfA *= bsdfRevPdfW;

		return true;
	}

private:

	// Flags controlling computation according to the selected algorithm type
	bool mTraceLightPaths;
	bool mTraceCameraPaths;
	bool mConnectToCamera;
	bool mConnectToLightSource;
	bool mConnectToLightVertices;
	bool mMergeWithLightVerticesBB1D;

	// Flags of used estimator techniques (used when calling methods from outside)
	uint mEstimatorTechniques;

	// BB1D
	float                mBB1DMisWeightFactor;       // Weight factor of BB1D
	float                mBB1DNormalization;         // 1 / bb1d_light_path_count
	PTPBEvaluator		 Evaluator;           // Encapsulates evaluating contributions of their intersections with beams
	float                mBB1DRadius;         // Initial merging radius
	float                mBB1DTime;
	float				 mDefaultLightSpeed;
	float                mBB1DRadiusAlpha;     	// Radius reduction rate parameter
	RadiusCalculation    mBB1DRadiusCalculation;     // Type of photon radius calculation
	int	                 mBB1DRadiusKNN;             // Value x means that x-th closest beam vertex will be used for calculation of cone radius at the current beam vertex
	float                mBB1DMinMFP;                // Minimum MFP of medium to store photon beams in it
	BeamType             mPhotonBeamType;            // Short/long beam
	float                mBB1DUsedLightSubPathCount; // First mBB1DUsedLightSubPathCount out of mLightSubPathCount light paths will generate photon beams
	float                mBB1DBeamStorageFactor;     // Factor used for computation of minimum MFP of media where photon beams are used. The lower it is the denser media will use photon beams.

	float mScreenPixelCount;         // Number of pixels
	float mLightSubPathCount;        // Number of light sub-paths
	float mRefPathCountPerIter;      // Reference number of paths per iteration
	float mPathCountPerIter;         // Number of paths per iteration

	size_t mLightVerticesOnSurfaceCount; // Number of light vertices located on surface
	size_t mLightVerticesInMediumCount;  // Number of light vertices located in medium

	std::vector<UPBPLightVertex> mLightVertices;          // Stored light vertices
	MisData mCameraVerticesMisData[PTPB_CAMERA_MAXVERTS]; // Stored MIS data for camera vertices (we don't need store whole vertices as for light paths)
	PTPBBeamsArray mPhotonBeamsArray;	                  // Stored photon beams

	VolumeSegments mVolumeSegments;         // Path segments intersecting media (up to scattering point)
	LiteVolumeSegments mLiteVolumeSegments; // Lite path segments intersecting media (up to intersection with solid surface)

	// For light path belonging to pixel index [x] it stores
	// where it's light vertices end (begin is at [x-1])
	std::vector<int> mPathEnds;

	// Used algorithm
	AlgorithmType mAlgorithm;

	// Random number generator
	Rng mRng;

	// Minimum distance from camera at which scattering events in media can occur
	float mMinDistToMed;

	int mBaseSeed;

	// Whether to ignore fully specular paths from camera
	bool mIgnoreFullySpecPaths;

	// Whether to print information about progress
	bool mVerbose;

	// Maximum memory for light vertices in thread
	size_t mMaxMemoryPerThread;

	Timer mTimer;
};

#endif //__PTPB_HXX__